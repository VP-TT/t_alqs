import os
import re
from flask import Flask, request, jsonify
from flask_cors import CORS
import torch
from transformer_model import build_transformer
from summarization import summarize
from transformers import T5Tokenizer, T5ForConditionalGeneration

app = Flask(__name__)
CORS(app)

MODEL_CONFIG = {
    "src_vocab_size": 30522,
    "tgt_vocab_size": 30522,
    "src_seq_len": 512,
    "tgt_seq_len": 512,
    "d_model": 512,
    "N": 6,
    "h": 8,
    "dropout": 0.1,
    "d_ff": 2048
}

def initialize_model():
    model = build_transformer(**MODEL_CONFIG)
    model.load_state_dict(torch.load(
        r"C:\Users\RAMA\Downloads\transformer_model_weights_epoch_6_loss_3.3377.pth",
        map_location='cpu'
    ))
    model.eval()
    return model

try:
    model = initialize_model()
    print("✅ Model loaded successfully")
except Exception as e:
    print(f"❌ Model loading failed: {str(e)}")
    model = None

@app.route('/')
def health_check():
    return jsonify({
        "status": "Operational",
        "model_loaded": bool(model)
    }), 200



@app.route('/summarize', methods=['POST'])
def summarize_text():
    if not model:
        return jsonify({"error": "Model not available"}), 503
    
    data = request.get_json()
    text = data.get('text', '')
    
    if not text:
        return jsonify({'error': 'No text provided'}), 400
    
    try:
        summary = summarize(model, text)
        return jsonify({'summary': summary})
    
    except Exception as e:
        return jsonify({'error': str(e)}), 500











if __name__ == '__main__':
    app.run(host='0.0.0.0', port=5000, debug=True)
